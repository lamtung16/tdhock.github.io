---
layout: post
title: Collapse reshape benchmark
description: Comparison with data.table
---

[data.table](https://github.com/rdatatable/data.table) is an R package
for efficient data manipulation.  I have an NSF POSE grant about
expanding the open-source ecosystem of users and contributors around
`data.table`.  Part of that project is benchmarking time and memory
usage, and comparing with similar packages.  Similar to previous posts
about
[reshaping](https://tdhock.github.io/blog/2024/reshape-performance/)
and
[reading/writing/summarization](https://tdhock.github.io/blog/2023/dt-atime-figures/),
the goal of this post is to explain how to use
[atime](https://github.com/tdhock/atime) to benchmark `data.table`
reshape with similar packages.

```{r Ropts, echo=FALSE}
repo.dir <- normalizePath("..")
post.id <- "2024-08-05-collapse-reshape"
fig.path <- file.path(repo.dir, "assets", "img", post.id)
knitr::opts_chunk$set(
  dpi=100,
  fig.path=paste0(fig.path, "/"),
  fig.width=8,
  fig.process=function(path)sub(repo.dir, "", path, fixed=TRUE),
  fig.height=4)
options(width=120)
if(FALSE){
  knitr::knit(paste0(post.id, ".Rmd"))
}
```

## Background about data reshaping

Data reshaping means changing the shape of the data, in order to get
it into a more appropriate format, for learning/plotting/etc. It is
perhaps best explained using a simple example. Here we consider the
iris data, which has four numeric columns, and we show the first two rows below:

```{r}
(two.iris.wide <- iris[c(1,150),])
```

Note the table above has 8 numbers, arranged into a table of 2 rows
and 4 columns. What if we wanted to make a facetted histogram of the
numeric iris data columns, with one panel/facet for each column? With
ggplots we have to first reshape to "long" (or I like to say "tall")
format:

```{r}
cols.to.reshape <- c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")
two.iris.wide.mat <- as.matrix(two.iris.wide[,cols.to.reshape])
row.i <- as.integer(row(two.iris.wide.mat))
(two.iris.tall <- data.frame(
  row.i,
  Species=two.iris.wide$Species[row.i],
  row.name=rownames(two.iris.wide)[row.i],
  col.name=cols.to.reshape[as.integer(col(two.iris.wide.mat))],
  cm=as.numeric(two.iris.wide.mat)))
```

Note the table above has the same 8 numbers, but arranged into a table
of 8 rows and 1 column, which is the desired input for ggplots.

## Making a function

Here is how we would do it using a function:

```{r}
reshape_taller <- function(DF, col.i){
  orig.row.i <- 1:nrow(DF)
  wide.mat <- as.matrix(DF[, col.i])
  orig.col.i <- as.integer(col(wide.mat))
  other.values <- DF[, -col.i, drop=FALSE]
  rownames(other.values) <- NULL
  data.frame(
    orig.row.i,
    orig.row.name=rownames(DF)[orig.row.i],
    orig.col.i,
    orig.col.name=names(DF)[orig.col.i],
    other.values,
    value=as.numeric(wide.mat))
}
reshape_taller(two.iris.wide,1:4)
```

And below is with the full iris data set:

```{r hist}
iris.tall <- reshape_taller(iris,1:4)
library(ggplot2)
ggplot()+
  geom_histogram(aes(
    value),
    bins=50,
    data=iris.tall)+
  facet_wrap("orig.col.name")
```

## Comparison with other functions

The function defined above works, and there are other functions which
provide similar functionality. For example,

```{r}
head(stats::reshape(
  iris, direction="long", varying=list(cols.to.reshape), v.names="cm"))
library(data.table)
iris.dt <- data.table(iris)
melt(iris.dt, measure.vars=cols.to.reshape, value.name="cm")
tidyr::pivot_longer(iris, cols.to.reshape, values_to = "cm")
head(collapse::pivot(iris, values=cols.to.reshape, names=list("variable", "cm")))
```

Below we define a larger version of iris data, as a function of number
of rows `N`:

```{r}
N <- 250
(row.id.vec <- 1+(seq(0,N-1) %% nrow(iris)))
N.df <- iris[row.id.vec,]
(N.dt <- data.table(N.df))
```

Below we use `atime` to compare the performance of the reshape
functions:

```{r atime-tall}
a.res <- atime::atime(
  N=2^seq(1,50),
  setup={
    (row.id.vec <- 1+(seq(0,N-1) %% nrow(iris)))
    N.df <- iris[row.id.vec,]
    (N.dt <- data.table(N.df))
  },
  seconds.limit=0.1,
  "stats\nreshape"=suppressWarnings(stats::reshape(N.df, direction="long", varying=list(cols.to.reshape), v.names="cm")),
  "data.table\nmelt"=melt(N.dt, measure.vars=cols.to.reshape, value.name="cm"),
  "tidyr\npivot_longer"=tidyr::pivot_longer(N.df, cols.to.reshape, values_to = "cm"),
  "collapse\npivot"=collapse::pivot(N.df, values=cols.to.reshape, names=list("variable", "cm")))
a.refs <- atime::references_best(a.res)
a.pred <- predict(a.refs)
plot(a.pred)+coord_cartesian(xlim=c(1e2,1e7))
```

The result above shows that `collapse` is fastest, but `data.table` is
almost as fast (by small a constant factor).

## Regex and multiple column support

In my [paper about the nc
package](https://journal.r-project.org/archive/2021/RJ-2021-029/index.html),
I proposed a new syntax for defining wide-to-tall reshape operations,
using regular expressions (regex). The motivating example in that
paper was a scatterplot to show that Sepals are larger than
Petals, as we see in the code/plot below.

```{r iris-scatter}
iris.parts <- nc::capture_melt_multiple(iris.dt, column=".*", "[.]", dim=".*")
ggplot()+
  geom_point(aes(
    Petal, Sepal, color=Species),
    data=iris.parts)+
  facet_grid(. ~ dim, labeller=label_both)+
  coord_equal()+
  theme_bw()+
  geom_abline(slope=1, intercept=0, color="grey50")
```

Other ways to do that reshape operation are shown in the code below:

```{r}
stats::reshape(two.iris.wide, cols.to.reshape, direction="long", timevar="dim", sep=".")
melt(data.table(two.iris.wide), measure.vars=measure(value.name, part, pattern="(.*)[.](.*)"))
tidyr::pivot_longer(two.iris.wide, cols.to.reshape, names_pattern = "(.*)[.](.*)", names_to = c(".value","part"))
```

However `?collapse::pivot` explains that it "currently does not
support concurrently melting/pivoting longer to multiple columns."
Below we compare the performance of these methods:

```{r atime-regex}
r.res <- atime::atime(
  N=2^seq(1,50),
  setup={
    (row.id.vec <- 1+(seq(0,N-1) %% nrow(iris)))
    N.df <- iris[row.id.vec,]
    (N.dt <- data.table(N.df))
  },
  seconds.limit=0.1,
  "nc::capture\nmelt_multiple"=nc::capture_melt_multiple(N.dt, column=".*", "[.]", dim=".*"),
  "stats\nreshape"=stats::reshape(N.df, cols.to.reshape, direction="long", timevar="dim", sep="."),
  "data.table\nmeasure"=melt(N.dt, measure.vars=measure(value.name, part, pattern="(.*)[.](.*)")),
  "tidyr\nnames_pattern"=tidyr::pivot_longer(N.df, cols.to.reshape, names_pattern = "(.*)[.](.*)", names_to = c(".value","part")))
r.refs <- atime::references_best(r.res)
r.pred <- predict(r.refs)
plot(r.pred)+coord_cartesian(xlim=c(1e2,1e7))
```

## Reshape wider

Above we did a wide to tall reshape. The inverse of that operation is
a tall to wide reshape,

```{r}
matrix(
  two.iris.tall$cm, nrow(two.iris.wide), length(cols.to.reshape),
  dimnames = list(
    two.iris.tall$row.name[1:nrow(two.iris.wide)],
    cols.to.reshape))
```

More generically to do that, we would need to consider missing
entries, as in the code below.

```{r}
reshape_wider <- function(DF){
  dimnames <- list()
  other.names <- setdiff(
    names(DF),
    c("orig.row.i", "orig.row.name", "orig.col.i", "orig.col.name", "value"))
  for(dim.type in c('row','col')){
    f <- function(suffix)paste0('orig.',dim.type,'.',suffix)
    u <- unique(DF[, c(
      f(c("i","name")),
      if(dim.type=='row')other.names
    )])
    s <- u[order(u[,f("i")]), ]
    dimnames[[dim.type]] <- s[, f("name")]
    if(dim.type=='row')other.df <- s[,other.names,drop=FALSE]
  }
  mat <- matrix(
    NA_real_, length(dimnames$row), length(dimnames$col),
    dimnames = dimnames)
  mat[cbind(DF$orig.row.i, DF$orig.col.i)] <- DF$value
  data.frame(mat, other.df)
}
(missing.one <- reshape_taller(two.iris.wide,1:4)[-1,])
reshape_wider(missing.one)
```

Other functions for doing that below:

```{r}
library(data.table)
N.tall.df <- reshape_taller(N.df,1:4)
str(reshape_wider(N.tall.df))
N.tall.dt <- data.table(N.tall.df)
str(dcast(N.tall.dt, orig.row.i ~ orig.col.name, value.var = "value"))
str(stats::reshape(N.tall.df, direction = "wide", idvar=c("orig.row.i","Species"), timevar="orig.col.name", v.names="value"))
str(tidyr::pivot_wider(N.tall.df, names_from=orig.col.name, values_from=value, id_cols=orig.row.i))
str(collapse::pivot(N.tall.df, how="w", ids="orig.row.i", values="value", names="orig.col.name"))
```

In all of the code examples above there are a few common elements

* ID: used to identify unique output rows must be specified, 
* Name: used for column names of output,
* Value: used to fill in elements of output.

| function             | ID             | Name           | Value         |
|----------------------|----------------|----------------|---------------|
| `data.table::dcast`  | LHS of formula | RHS of formula | `value.var`   |
| `stats::reshape`     | `idvar`        | `timevar`      | `v.names`     |
| `tidyr::pivot_wider` | `id_cols`      | `names_from`   | `values_from` |
| `collapse::pivot`    | `ids`          | `names`        | `values`      |

Timings below

```{r atime-wide}
w.res <- atime::atime(
  N=2^seq(1,50),
  setup={
    (row.id.vec <- 1+(seq(0,N-1) %% nrow(iris)))
    N.df <- iris[row.id.vec,]
    N.tall.df <- reshape_taller(N.df,1:4)
    N.tall.dt <- data.table(N.tall.df)
  },
  seconds.limit=0.1,
  "data.table\ndcast"=dcast(N.tall.dt, orig.row.i ~ orig.col.name, value.var = "value"),
  "stats\nreshape"=suppressWarnings(stats::reshape(N.tall.df, direction = "wide", idvar=c("orig.row.i","Species"), timevar="orig.col.name", v.names="value")),
  "tidyr\npivot_wider"=tidyr::pivot_wider(N.tall.df, names_from=orig.col.name, values_from=value, id_cols=orig.row.i),
  "collapse\npivot"=collapse::pivot(N.tall.df, how="w", ids="orig.row.i", values="value", names="orig.col.name"))
w.refs <- atime::references_best(w.res)
w.pred <- predict(w.refs)
plot(w.pred)+coord_cartesian(xlim=c(NA,1e7))
```

The comparison above shows that `collapse` is actually a bit faster
than `data.table`, for this tall to wide reshape operation which
involved just copying data (no summarization). But close inspection of
the log-log plot above shows different slopes for the different lines,
which suggests that they have different asymptotic complexity
classes. To estimate them, we use the code below,

```{r atime-wide-refs}
plot(w.refs)
```

The plot above suggests that all methods have the same linear asymptotic memory usage, O(N).
But `data.table` is the only method which is clearly linear time.

* `collapse::pivot` and `tidyr::pivot_wider` appear to be log-linear, O(N log N).
* `stats::reshape` appears between linear and log-linear.

## Reshape wider with summarization

Sometimes we want to do a reshape wider operation with summarization
functions. For example, in the code below, we use `mean` for every `orig.col.name` and `Species`:

```{r}
dcast(N.tall.dt, orig.col.name + Species ~ ., mean)
stats::aggregate(N.tall.df[,"value",drop=FALSE], by=with(N.tall.df, list(orig.col.name=orig.col.name,Species=Species)), FUN=mean)
N.tall.df$name <- "foo"
tidyr::pivot_wider(N.tall.df, names_from=name, values_from=value, id_cols=c(orig.col.name,Species), values_fn=mean)
collapse::pivot(N.tall.df, how="w", ids=c("orig.col.name","Species"), values="value", names="name", FUN=mean)
```

Note in the code above that to get the `tidyr` and `collapse` methods
to work, a "name" column must be created, whereas in `data.table` it
not necessary (you just specify `.` in right side of formula to
indicate that only one column should be output). The table below summarizes the differences in syntax between the different R functions:

| function             | ID             | Name             | Value            | Aggregation     |
|----------------------|----------------|------------------|------------------|-----------------|
| `data.table::dcast`  | LHS of formula | RHS of formula   | `value.var`      | `fun.aggregate` |
| `stats::aggregate`   | `by`           | all column names | all input values | `FUN`           |
| `tidyr::pivot_wider` | `id_cols`      | `names_from`     | `values_from`    | `values_fn`     |
| `collapse::pivot`    | `ids`          | `names`          | `values`         | `FUN`           |

Below we compare the performance of these different functions.

```{r atime-agg}
m.res <- atime::atime(
  N=2^seq(1,50),
  setup={
    (row.id.vec <- 1+(seq(0,N-1) %% nrow(iris)))
    N.df <- iris[row.id.vec,]
    N.tall.df <- reshape_taller(N.df,1:4)
    N.tall.df$name <- "foo"
    N.tall.dt <- data.table(N.tall.df)
  },
  seconds.limit=0.1,
  "stats\naggregate"=stats::aggregate(N.tall.df[,"value",drop=FALSE], by=with(N.tall.df, list(orig.col.name=orig.col.name,Species=Species)), FUN=mean),
  "tidyr\npivot_wider"=tidyr::pivot_wider(N.tall.df, names_from=name, values_from=value, id_cols=c(orig.col.name,Species), values_fn=mean),
  "collapse\npivot"=collapse::pivot(N.tall.df, how="w", ids=c("orig.col.name","Species"), values="value", names="name", FUN=mean),
  "data.table\ndcast"=dcast(N.tall.dt, orig.col.name + Species ~ ., mean))
m.refs <- atime::references_best(m.res)
m.pred <- predict(m.refs)
plot(m.pred)+coord_cartesian(xlim=c(NA,1e7))
```

The result above shows that `data.table` is a bit faster than
`collapse`. Upon close inspection of the log-log plot above, we see
that `data.table` has a smaller slope than `collapse`, which means
that `data.table has an asymptotically more efficient complexity
class. To estimate the asymptotic complexity class, we can use the
plot below.

```{r atime-agg-refs}
plot(m.refs)
```

The plot above indicates that `collapse` is asymptotically log-linear,
`O(N log N)`, in the number of input rows `N`, whereas the others are
linear, `O(N)`.

## Multiple aggregation functions

It is often useful to provide a list of aggregation functions, instead of just one. For example, in visualization results of machine learning predictions, we would like to use

* `mean` to compute the mean prediction error over several train/test splits,
* `sd` to get the standard deviation,
* `length` to double-check that the number of items to summarize is the same as the number of cross-validation folds.

In `data.table` we can provide a list of functions as in the code below,

```{r}
dcast(N.tall.dt, orig.col.name + Species ~ ., list(mean, sd, length))
```

However this feature is not supported in other packages. 

* `?stats::aggregate` says "FUN: a function to compute the summary
  statistics which can be applied to all data subsets."
* `?collapse::pivot` says "FUN: function to aggregate values. At
  present, only a single function is allowed."
* `?tidyr::pivot_wider` says `values_fn` argument "can be a named list
  if you want to apply different aggregations to different
  `values_from` columns."

## Conclusion

We have shown how to use `atime` to check if there are any performance
differences between data reshaping functions in R. We observed large
differences between functions when doing a reshape in the wider
direction, with no aggregation (`collapse` is about 50x faster than
`data.table` for this case, which involves just copying values to a
new table). For reshape in the tall/long direction, and for reshape
wider with aggregation, we observed small constant factor differences
between methods (`collapse` was still fastest but by only 2x).

In terms of functionality, we observed a few differences. Wide-to-tall
reshape defined by a `regex` is supported by
`tidyr::pivot_longer(names_pattern=regex)` and
`data.table::measure(pattern=regex)`, whereas `stats::reshape` only
supports multiple outputs via the `sep` argument (separator, not
regex), and `collapse::pivot` does not support multiple outputs at
all. Also, we observed that `data.table::dcast` is the only function
that supports multiple aggregation functions, which can be useful for
simultaneously computing a variety of summary statistics, such as
`mean`, `sd`, and `length`. The table below summarizes these
differences in functionality.

|              | reshape long     | reshape long | reshape wide  | reshape wide | reshape wide |
| package      | multiple outputs | using regex  | multiple agg. | single agg.  | no agg.      |
|--------------|------------------|--------------|---------------|--------------|--------------|
| `data.table` | yes              | yes          | yes           | O(N)         | O(N)         |
| `tidyr`      | yes              | yes          | no            | O(N)         | O(N log N)   |
| `stats`      | yes              | no           | no            | O(N)         | O(N log N)   |
| `collapse`   | no               | no           | no            | O(N log N)   | O(N log N)   |

For future work, 

* `data.table`/`tidyr` may consider trying to speed up the constant factors in the reshape wide code without aggregation.
* `collapse` reshape wide with aggregation is currently asymptotically log-linear, and so may consider speeding up to be asymptotically linear.
* `tidyr`/`collapse` may consider implementing the advanced reshaping features that `data.table` currently supports (multiple outputs, regex).

## Session info

```{r}
sessionInfo()
```
