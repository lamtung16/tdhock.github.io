---
layout: post
title: AUC and AUM in torch
description: Demonstration of auto-grad
---

```{r Ropts, echo=FALSE}
repo.dir <- normalizePath("..")
post.id <- "2024-10-10-torch-roc-aum"
fig.path <- file.path(repo.dir, "assets", "img", post.id)
knitr::opts_chunk$set(
  dpi=100,
  fig.path=paste0(fig.path, "/"),
  fig.width=10,
  fig.process=function(path)sub(repo.dir, "", path, fixed=TRUE),
  fig.height=4)
conda.env <- "2023-08-deep-learning"
Sys.setenv(RETICULATE_PYTHON=sprintf(if(.Platform$OS.type=="unix")
  ##"/home/tdhock/.local/share/r-miniconda/envs/%s/bin/python"
  "/home/tdhock/miniconda3/envs/%s/bin/python"
  else "~/Miniconda3/envs/%s/python.exe", conda.env))
reticulate::use_condaenv(conda.env, required=TRUE)
in_render <- !is.null(knitr::opts_knit$get('rmarkdown.pandoc.to'))
in_knit <- isTRUE(getOption('knitr.in.progress'))
options(width=120)
if(FALSE){
  knitr::knit(paste0(post.id, ".Rmd"))
}
```

The goal of this post is to show how to use torch to compute ROC-AUC
(classic evaluation metric for binary classification) and AUM (Area
Under Min of False Positive and False Negative rates, our newly
proposed surrogate loss for ROC curve optimization).

## Introduction

In supervised binary classification, our goal is to learn a function
`f` using training inputs/features `x`, and outputs/labels `y`, such
that `f(x)=y` (on new/test data).  The classic objective function for
evaluation is the zero-one loss, which computes the number/proportion
of labels which are mis-classified (in the test set).

In imbalanced data, for example with 99% negative and 1% positive
labels, other objective functions like AUC (Area Under ROC Curve) are
used for evaluation. The [Receiver Operating Characteristic (ROC)
curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)
is a plot of True Positive Rate, as a function of False Positive Rate,
for all possible thresholds of the predicted score `f(x)` for an input
feature vector `x`.  I like to think of the ROC curve as a 2D
parametric function: `[FPR(c),TPR(c)]`, where

* the parameter is `c`, a constant that could be added to predicted
  scores, before using the threshold of zero to determine whether we
  should predict if the class is positive (`f(x)+c > 0`) or negative
  (`f(x)+c < 0`).
* If `c` is very small, then `f(x_i)+c < 0` for all data `i`, so
  `FPR(c)=0` and `TPR(c)=0` (all data classified as negative).
* If `c` is very large, then `f(x_i)+c

```{python echo=FALSE}
repo_dir = r["repo.dir"]
fig_path = r["fig.path"]
import warnings
def p9_save(g, name):
    out_png = fig_path+name+".png"
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        g.save(out_png)
    web_link = out_png.replace(repo_dir, "")
    print('![plot of %s](%s)'%(name, web_link))
# work-around for rendering plots under windows, which hangs within
# emacs python shell: instead write a PNG file and view in browser.
import os
import webbrowser
on_windows = os.name == "nt"
rendering = r.rendering if 'r' in dir() else False
using_agg = on_windows and not rendering
if using_agg:
    import matplotlib
    matplotlib.use("agg")
def show(g, name):
    if not using_agg:
        return p9_save(g, name)
    g.save("tmp.png")
    webbrowser.open('tmp.png')
```

TODO

Below I wrote an implementation of our AUM loss function, 

```{python}
import torch
import pandas as pd

def ROC_curve(pred_tensor, label_tensor):
    """Receiver Operating Characteristic curve

    """
    is_positive = label_tensor == 1
    is_negative = label_tensor != 1
    fn_diff = torch.where(is_positive, -1, 0)
    fp_diff = torch.where(is_positive, 0, 1)
    thresh_tensor = -pred_tensor.flatten()
    sorted_indices = torch.argsort(thresh_tensor)
    fp_denom = torch.sum(is_negative) #or 1 for AUM based on count instead of rate
    fn_denom = torch.sum(is_positive) #or 1 for AUM based on count instead of rate
    sorted_fp_cum = fp_diff[
        sorted_indices].cumsum(axis=0)/fp_denom
    sorted_fn_cum = -fn_diff[
        sorted_indices].flip(0).cumsum(axis=0).flip(0)/fn_denom
    sorted_thresh = thresh_tensor[sorted_indices]
    sorted_is_diff = sorted_thresh.diff() != 0
    sorted_fp_end = torch.cat([sorted_is_diff, torch.tensor([True])])
    sorted_fn_end = torch.cat([torch.tensor([True]), sorted_is_diff])
    uniq_thresh = sorted_thresh[sorted_fp_end]
    uniq_fp_after = sorted_fp_cum[sorted_fp_end]
    uniq_fn_before = sorted_fn_cum[sorted_fn_end]
    FPR = torch.cat([torch.tensor([0.0]), uniq_fp_after])
    FNR = torch.cat([uniq_fn_before, torch.tensor([0.0])])
    return {
        "FPR":FPR,
        "FNR":FNR,
        "TPR":1 - FNR,
        "min":torch.minimum(FPR, FNR),
        "min_thresh":torch.cat([torch.tensor([-torch.inf]), uniq_thresh]),
        "max_thresh":torch.cat([uniq_thresh, torch.tensor([torch.inf])])
    }

def Proposed_AUM(pred_tensor, label_tensor):
    """Area Under Min(FP,FN)

    Differentiable loss function for imbalanced binary classification
    problems. Minimizing AUM empirically results in maximizing Area
    Under the ROC Curve (AUC). Arguments: pred_tensor and label_tensor
    should both be 1d tensors, vectors of real-valued predictions and
    integer labels for each observation in the set/batch. Labels
    should be either 1 for positive class or any other value for
    negative class.

    """
    roc = ROC_curve(pred_tensor, label_tensor)
    return torch.sum(roc["min"][1:-1] * roc["min_thresh"][1:].diff())

def ROC_AUC(pred_tensor, label_tensor):
    roc = ROC_curve(pred_tensor, label_tensor)
    FPR_diff = roc["FPR"][1:]-roc["FPR"][:-1]
    TPR_sum = roc["TPR"][1:]+roc["TPR"][:-1]
    return torch.sum(FPR_diff*TPR_sum/2.0)
    
label_vec = torch.tensor([0,0,1,1])
pred_vec = torch.tensor([1.0, -1, 1, 0])
pred_vec = torch.tensor([1.0, 2, 3, 4])
Proposed_AUM(pred_vec, label_vec)
ROC_AUC(pred_vec, label_vec)

roc_wide = pd.DataFrame(ROC_curve(pred_vec, label_vec))
roc_long = pd.melt(
    roc_wide,
    value_vars=["FPR","FNR","min"],
    id_vars=["min_thresh","max_thresh"])

import plotnine as p9
gg = p9.ggplot()+\
    p9.geom_segment(
        p9.aes(
            x="min_thresh",
            xend="max_thresh",
            y="value",
            yend="value",
            color="variable",
            size="variable"
        ),
        data=roc_long)+\
    p9.scale_color_manual(
        values={
            "FPR":"red",
            "FNR":"deepskyblue",
            "min":"black"
        })+\
    p9.scale_size_manual(
        values={
            "FPR":3,
            "FNR":5,
            "min":1,
        })
gg
show(gg, "err_funs")
```

The implementation above consists of vectorized torch operations, all
of which should be differentiable almost everywhere. To check the
automatically computed gradient from torch with the directional
derivatives described in our paper, we can use the backward method,

```{python}
label_vec = [0, 1]
pred_diff_vec = torch.arange(-2, 2, 0.5)
obj_grad_df_list = []
for pred_diff in pred_diff_vec:
    pred_vec = [0, pred_diff]
    for objective in "Proposed_AUM","ROC_AUC":
        pred_tensor = torch.tensor(pred_vec)
        pred_tensor.requires_grad = True
        label_tensor = torch.tensor(label_vec)
        ofun = eval(objective)
        loss = ofun(pred_tensor, label_tensor)
        try:
            loss.backward()
            g_vec = pred_tensor.grad
        except:
            g_vec = torch.tensor([0.0, 0])
        obj_grad_df_list.append(pd.DataFrame({
            "pred_diff":pred_diff.numpy(),
            "objective":objective,
            "function":["output","deriv0","deriv1"],
            "value":torch.cat([loss.reshape(1),g_vec]).detach().numpy(),
        }))
obj_grad_df = pd.concat(obj_grad_df_list)

p9.ggplot()+\
    p9.theme_bw()+\
    p9.geom_hline(
        p9.aes(
            yintercept="value"
        ),
        data=pd.DataFrame({"value":[0]}),
        color="grey"
    )+\
    p9.geom_point(
        p9.aes(
            x="pred_diff",
            y="value",
        ),
        data=obj_grad_df
    )+\
    p9.facet_grid("function ~ objective", labeller="label_both")
    
```

## Simple differentiable points

Let us consider an example from the aum R package,

```{r}
bin.diffs <- aum::aum_diffs_binary(c(0,1))
aum::aum(bin.diffs, c(-10,10))
```

The R code and output above shows that for one negative label with
predicted value -10, and one positive label with predicted value 10,
we have AUM=0 and directional derivatives are also zero. That is also
seen in the python code below:

```{python}
y_list = [0, 1]
def loss_grad(pred_vec, label_vec):
    pred_tensor = torch.tensor(pred_vec)
    pred_tensor.requires_grad = True
    label_tensor = torch.tensor(label_vec)
    loss = AUM(pred_tensor, label_tensor)
    loss.backward()
    return loss, pred_tensor.grad
loss_grad([-10.0, 10.0], y_list)
```

Another example is for the same labels but the opposite predicted
values, for which the R code is below,

```{r}
aum::aum(bin.diffs, c(10,-10))
```

The R code and output above shows that we have AUM=20 and derivative 1
for the first/negative example, and derivative -1 for the
second/positive example. Those derivatives indicate that the AUM can
be decreased by decreasing the predicted value for the first/negative
example and/or increasing the predicted vale for the second/positive
example. Consistent results can be observed from the python code
below,

```{python}
loss_grad([10.0, -10.0], y_list)
```

## Non-differentiable points

As discussed in our paper, the AUM is not differentiable everywhere.
So what happens when you use auto-grad on a non-differentiable loss?
Apparently the backward method returns a subgradient, as explained in
[an issue discussing autograd of L1 loss
function](https://github.com/pytorch/pytorch/issues/7172).

One example, again taken from the aum R package, is when both
predicted values are zero,

```{r}
aum::aum(bin.diffs, c(0,0))
```

The output above indicates AUM=0 with directional derivatives which
are not equal on the left and right. The first row of the directional
derivative matrix says that decreasing the first/negative predicted
value will result in no change to AUM, whereas increasing will result
in increasing AUM. The second row says that decreasing the
second/positive predicted value results in increasing AUM, whereas
increasing the predicted value results in no change to AUM. Is the
python torch auto-grad code consistent?

```{python}
loss_grad([0.0, 0.0], y_list)
```

The output above says that the gradient is zero, which is OK (these
predicted values are a minimum) but it is missing some information
about what happens nearby.

## Non-convex points

The implementation above of AUM is only for binary classification, but
in our paper we also discuss an application to changepoint detection
problems. In the case of changepoint detection problems with
non-monotonic error functions, the AUM may be non-convex, and there
may be points at which there are no subgradients. Some are used as
[test cases in our R package](https://github.com/tdhock/aum/blob/main/tests/testthat/test-CRAN.R).
What does auto-grad return in that case? (exercise for the reader)

Update Aug 2024. The `AUM` function above uses the minimum of total FP and FN, whereas there now is a more complete python AUM implementation which can use rates (FPR/FNR) rather than totals.

* [rate only](https://github.com/tdhock/max-generalized-auc/blob/master/data_Classif.py#L41)
* [count total or rate](https://github.com/tdhock/max-generalized-auc/blob/master/figure-aum-neural-networks-data.py#L83)


## Conclusions

TODO

## Session info

```{r}
sessionInfo()
```
