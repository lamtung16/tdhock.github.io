---
layout: post
title: Defining data by row and regex by sub-pattern
description: Avoiding separation of related concepts in code
---

My [paper about regular expressions for data
reshaping](https://github.com/tdhock/nc-article) was recently accepted
into R journal. It describes the novelty of my
[nc](https://github.com/tdhock/nc) R package, which solves the problem
of "separation of related concepts" which happens with other data
reshaping packages. I wrote "the nc syntax should be preferred for
more complex patterns (with more groups) in order to keep the group
names and sub-patterns closer and easier to maintain/read in the
code." This is related to the idea that a data table is often easier
to read/edit when defined as a collection of rows (versus columns).

## medRxiv paper code example

In [our recent paper about spatially explicit stochastic disease
models](https://www.medrxiv.org/content/10.1101/2021.05.13.21256216v1)
(currently in peer review), there is some R code that defines time
windows. It was my suggestion to present the data/code as follows,
with each time window on a line:

```{r}
one.window <- function(start, end, r0)data.frame(start, end, r0)
library(lubridate)
(time.window.args <- rbind(# Specify the components of 5 time windows
  one.window(mdy("1-1-20"),mdy("1-31-20"),3.0),
  one.window(mdy("2-1-20"),mdy("2-15-20"),0.8),
  one.window(mdy("2-16-20"),mdy("3-10-20"),0.8),
  one.window(mdy("3-11-20"),mdy("3-21-20"),1.4),
  one.window(mdy("3-22-20"),mdy("5-1-20"),1.4)))
```

The code above is easy to read because all of the information related
to a given time window is defined on the same line. It is easy to
add/remove/change windows for the same reason.  In contrast, another
way to define these data would be with a column on each line,

```{r, echo=FALSE, results="hide"}
tw.chr <- time.window.args
for(col.name in c("start", "end")){
  col.chr <- strftime(time.window.args[[col.name]], "%_m-%_d-%y")
  tw.chr[[col.name]] <- gsub(" ", "", col.chr)
}
dput(tw.chr)
```

```{r}
data.frame(
  start=c("1-1-20","2-1-20","2-16-20","3-11-20","3-22-20"),
  end=c("1-31-20","2-15-20","3-10-20","3-21-20","5-1-20"),
  r0=c(3,0.8,0.8,1.4,1.4))
```

This format above is much more difficult to read and understand --
what is the r0 value for Mar 17? You have to first figure out that day
falls in the fourth start/end, then you have to find the fourth r0
value. Reading is a bit easier if you add a bunch of spaces, as below:

```{r}
data.frame(
  start =c( "1-1-20", "2-1-20", "2-16-20", "3-11-20", "3-22-20"),
  end   =c("1-31-20","2-15-20", "3-10-20", "3-21-20",  "5-1-20"),
  r0    =c(        3,      0.8,       0.8,       1.4,       1.4))
```

Column-wise storage also makes it more difficult to add/remove/edit
entries. This observation helps to explain why CSV files are such a
popular data storage format.

## Analog with regular expressions for data reshaping

In wide-to-long data reshaping with regular column names we can use a
regex pattern to (1) identify the input columns to reshape, and (2)
extract data from those columns for storage in the output. For example
consider the following data, 

```{r}
# similar to data(who, package="tidyr")
who <- data.frame(country="usa", new_sp_m5564=1, newrel_f65=2, new_ep_f014=3)
```

Each column after the first has a regular name: 

* new,
* an optional underscore,
* a diagnosis code (sp|rel|ep),
* sex (m|f),
* a min age in years,
* an optional max age.

Say we want to reshape these "wide" data into a "longer" table with
columns `diagnosis`, `sex`, `min_years`, `max_years`. The most basic
method is by using a capturing regular expression,

```{r}
pattern <- "new_?(.*)_(.)(0|[1-9]{2})([0-9]{0,2})"
proto <- data.frame(
  diagnosis=character(),
  sex=character(),
  min_years=numeric(),
  max_years=numeric())
transform(
  strcapture(pattern, names(who), proto)
, max_years=ifelse(is.na(max_years) & is.finite(min_years), Inf, max_years))
```

Looking at the above code, we see a relatively complex regular
expression `pattern` with four capture groups. To use it with
`strcapture` we need to define `proto`, a data frame which specifies
the type of each output column. There are two drawbacks to notice with
this approach:

* types are defined in `proto` but converting NA to Inf must be done
  after `strcapture`, here using `transform`.
* there is separation between the definitions of the related concepts
  for each capture group (sub-pattern is defined in `pattern` whereas
  names and types defined in `proto`). 
  
An attempt to remove this separation:
  
```{r}
p <- function(regex, name=NA, type=NA, fun=NA)data.frame(regex, name, type, fun)
NA_to_Inf <- function(s){
  x <- as.numeric(s)
  ifelse(is.na(x), Inf, x)
}
(pattern.df <- rbind(
  p("new_?"),
  p("(.*)", "diagnosis", "character"),
  p("_"),
  p("(.)", "sex", "character"),
  p("(0|[1-9]{2})", "min_years", "numeric", "as.numeric"),
  p("([0-9]{0,2})", "max_years", "numeric", "NA_to_Inf")))
```

In the definition above, all of the information related to each
capture group is defined on the same line, so it is much easier to
read/edit! We can use it for doing the same computation via

```{r}
(my.pattern <- paste(pattern.df[["regex"]], collapse=""))
(my.proto <- with(pattern.df, {
  is.group <- !is.na(name)
  structure(
    lapply(type[is.group], function(tname)get(tname)()),
    names = name[is.group])
}))
(strcapture.out <- strcapture(my.pattern, names(who), my.proto))
```

We can furthermore use the `fun` column to automatically apply the
conversion to Inf:

```{r}
(t.fun.df <- subset(pattern.df, !is.na(fun)))
for(t.fun.i in 1:nrow(t.fun.df)){
  t.fun.row <- t.fun.df[t.fun.i,]
  fun <- get(t.fun.row[["fun"]])
  name <- t.fun.row[["name"]]
  value <- strcapture.out[[name]]
  strcapture.out[[name]] <- fun(value)
}
strcapture.out
```

So the code above demonstrates that it is techinically POSSIBLE to use
`strcapture` with a complex regex defined in a way that has all info
for a particular capture group on a single line. Furthermore we can
use the same info to do the reshape, using the new
`data.table::measurev()` function [which I recently
implemented](https://github.com/Rdatatable/data.table/pull/5022).

```{r}
library(data.table)
fun.list <- with(subset(pattern.df, !is.na(name)), {
  structure(lapply(fun, function(f)if(is.na(f))NULL else get(f)), names=name)
})
(who.dt <- data.table(who))
who.long <- data.table::melt(
  who.dt, measure.vars=measurev(fun.list, pattern=my.pattern))
print(who.long, class=TRUE)
```

The whole point of the `nc` package is that you can define your regex
in a similar way, so that there is one line which has all the related
info for each group (name, sub-pattern, conversion function). The `nc`
code which is analogous to the `pattern.df` code above would be

```{r}
nc.pattern <- list(
  "new_?",
  diagnosis=".*", 
  "_",
  sex=".", 
  min_years="0|[1-9]{2}", as.numeric,
  max_years="[0-9]{0,2}", function(x)ifelse(x=="", Inf, as.numeric(x)))
```

Having defined the pattern in this way, `nc` provides a function to do
the matching and capturing,

```{r}
capture.result <- nc::capture_first_vec(
  names(who), nc.pattern, nomatch.error = FALSE)
print(capture.result, class=TRUE)
``` 

and another function to do the reshaping,

```{r}
reshape.result <- nc::capture_melt_single(who, nc.pattern)
print(reshape.result, class=TRUE)
```

## Named capture groups in regex string literals

One other approach worth mentioning here is using regular expression
string literals with named capture groups. That would result in
something like

```{r}
n <- function(regex, type=NA, fun=NA)data.frame(regex, type, fun)
(named.pattern.df <- rbind(
  n("new_?"),
  n("(?P<diagnosis>.*)", "character"),
  n("_"),
  n("(?P<sex>.)", "character"),
  n("(?P<min_years>0|[1-9]{2})", "numeric", "as.numeric"),
  n("(?P<max_years>[0-9]{0,2})", "numeric", "NA_to_Inf")))
(named.pattern <- paste(named.pattern.df[["regex"]], collapse=""))
```

The names defined in those string literals can be parsed and output to
R with several functions,

```{r}
(exec.result <- regexec(named.pattern, names(who), perl=TRUE))
(match.result <- regmatches(names(who), exec.result))
match.result[sapply(match.result, length)==0] <- NA
do.call(rbind, match.result)
rex::matches(names(who), named.pattern)
rematch2::re_match(names(who), named.pattern)
re2r::re2_match(names(who), named.pattern)
```

The results above are all of type character, and can be converted to
numeric using the other information defined in `named.pattern.df` as
above. This approach using named capture groups in the regex string
literals does not have any substantial advantages to the previous
approach with un-named capture groups (storing the `name` in a
separate column of `pattern.df`).

## Conclusion

We have seen that defining a data table by row is much easier to
read/edit than definition by column. Likewise, it is possible to
define a complex regex in terms of sub-patterns together with related
info. We created a data table with one row per sub-pattern, and
columns for optional name, type, and conversion function. After
defining the regex in this manner, it is possible to derive all of the
information you need as input to various R functions (complete
pattern, group names, list of type conversion functions, etc). In
contrast to direct definition of these various inputs, the proposed
approach is much easier to read/edit, and is the main
idea/novelty/useful feature of the `nc` package.
